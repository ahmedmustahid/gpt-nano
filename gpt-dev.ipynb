{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841f9654-c058-4ef7-ab49-efb39b64e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f43234-80aa-41de-9bab-cbaba7e2b884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03f20d9-85a0-4884-9c98-0d1808e586f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e79dc-5550-4c77-8e21-cebbb46038e5",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e197cd05-5a9a-4413-a77d-80fb6807ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for i,s in enumerate(chars)}\n",
    "encode = lambda x: [stoi[c] for c in x]\n",
    "decode = lambda x: \"\".join([itos[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd691f00-18ed-497a-8119-6002e0628d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 1, 58, 46, 43, 56, 43]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d14274-8013-48f4-bf1d-33eda793836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi there'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([46, 47, 1, 58, 46, 43, 56, 43])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b10f6-19c3-4a2a-b42c-c12252c1f16a",
   "metadata": {},
   "source": [
    "#### Tensorizing tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac2a4de-fa10-468b-8eb8-5eed2cbe8e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3294827f-f442-47d8-9857-8355ac8beb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f516737a-8515-49b7-8261-a629a4ca797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18])--->47\n",
      "tensor([18, 47])--->56\n",
      "tensor([18, 47, 56])--->57\n",
      "tensor([18, 47, 56, 57])--->58\n",
      "tensor([18, 47, 56, 57, 58])--->1\n",
      "tensor([18, 47, 56, 57, 58,  1])--->15\n",
      "tensor([18, 47, 56, 57, 58,  1, 15])--->47\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])--->58\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "\n",
    "    print(f\"{context}--->{target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e6f36-4a13-4c87-a1cc-150b7609df6b",
   "metadata": {},
   "source": [
    "this is the time dimension. another dimension is batch dimension. chunks of data processed in gpu independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ec4b3-b0e2-4a66-a326-9d4e6b5e2235",
   "metadata": {},
   "source": [
    "### Creating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4076a4-942e-4b99-92f5-294c6b0374c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "input: [24]--->target: [43]\n",
      "input: [24, 43]--->target: [58]\n",
      "input: [24, 43, 58]--->target: [5]\n",
      "input: [24, 43, 58, 5]--->target: [57]\n",
      "input: [24, 43, 58, 5, 57]--->target: [1]\n",
      "input: [24, 43, 58, 5, 57, 1]--->target: [46]\n",
      "input: [24, 43, 58, 5, 57, 1, 46]--->target: [43]\n",
      "input: [24, 43, 58, 5, 57, 1, 46, 43]--->target: [39]\n",
      "input: [44]--->target: [53]\n",
      "input: [44, 53]--->target: [56]\n",
      "input: [44, 53, 56]--->target: [1]\n",
      "input: [44, 53, 56, 1]--->target: [58]\n",
      "input: [44, 53, 56, 1, 58]--->target: [46]\n",
      "input: [44, 53, 56, 1, 58, 46]--->target: [39]\n",
      "input: [44, 53, 56, 1, 58, 46, 39]--->target: [58]\n",
      "input: [44, 53, 56, 1, 58, 46, 39, 58]--->target: [1]\n",
      "input: [52]--->target: [58]\n",
      "input: [52, 58]--->target: [1]\n",
      "input: [52, 58, 1]--->target: [58]\n",
      "input: [52, 58, 1, 58]--->target: [46]\n",
      "input: [52, 58, 1, 58, 46]--->target: [39]\n",
      "input: [52, 58, 1, 58, 46, 39]--->target: [58]\n",
      "input: [52, 58, 1, 58, 46, 39, 58]--->target: [1]\n",
      "input: [52, 58, 1, 58, 46, 39, 58, 1]--->target: [46]\n",
      "input: [25]--->target: [17]\n",
      "input: [25, 17]--->target: [27]\n",
      "input: [25, 17, 27]--->target: [10]\n",
      "input: [25, 17, 27, 10]--->target: [0]\n",
      "input: [25, 17, 27, 10, 0]--->target: [21]\n",
      "input: [25, 17, 27, 10, 0, 21]--->target: [1]\n",
      "input: [25, 17, 27, 10, 0, 21, 1]--->target: [54]\n",
      "input: [25, 17, 27, 10, 0, 21, 1, 54]--->target: [39]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split==\"train\" else val_data\n",
    "    ix = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch(split=\"train\")\n",
    "print(f\"inputs: {xb}\")\n",
    "print(f\"targets: {yb}\")\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): #time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t:t+1]\n",
    "\n",
    "        print(f\"input: {context.tolist()}--->target: {target.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fac627-7bb5-4cac-86e2-93f0b5069d3c",
   "metadata": {},
   "source": [
    "### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f152e762-ca67-4482-8db4-b882a0ada7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 65])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self,ix, targets):\n",
    "        logits = self.embedding(ix)#B,T,C#batch, time, Channel(emb dim)\n",
    "        return logits\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "out = model(xb, yb)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724a94a-3e63-4a2b-a529-ff9036842e28",
   "metadata": {},
   "source": [
    "#### Obtaining loss (wrong pytorch syntax way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb98dc1c-6fcd-4733-84e8-c75f84cf68fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [4, 65], got [4, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m BigramLanguageModel(vocab_size)\n\u001b[0;32m---> 13\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[0;34m(self, ix, targets)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,ix, targets):\n\u001b[1;32m      7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(ix)\u001b[38;5;66;03m#B,T,C#batch, time, Channel(emb dim)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [4, 65], got [4, 8]"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self,ix, targets):\n",
    "        logits = self.embedding(ix)#B,T,C#batch, time, Channel(emb dim)\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "out = model(xb, yb)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66848d00-d195-4f4f-9c93-bf54d62e118e",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
    "\n",
    "Our dimension is B,T,C but torch expects B,C,T.\n",
    "\n",
    "we had better pass using the shape of B*T, C instead of B,T,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323d7a92-7d7e-4f5b-a54d-cca61fd5698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.4971, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self,ix, targets):\n",
    "        logits = self.embedding(ix)#B,T,C#batch, time, Channel(emb dim)\n",
    "\n",
    "        B,T,C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "out, loss = model(xb, yb)\n",
    "print(out.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e093a-04ec-45a5-99da-d239d6aed6bc",
   "metadata": {},
   "source": [
    "We have 65 vocab size. so probability for each to be randomly selected is 1/65. so random loss should be -log(1/65)=4.1743872698956. Our loss is larger than that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce930c-3d28-4e93-98c1-30b8293cb4db",
   "metadata": {},
   "source": [
    "#### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07a91aec-766c-4d93-b465-59fce9ee3e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self,ix, targets=None):\n",
    "        logits = self.embedding(ix)#B,T,C#batch, time, Channel(emb dim)\n",
    "\n",
    "        if targets==None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_token):\n",
    "\n",
    "        for _ in range(max_new_token):\n",
    "            logits, _ = self(idx)\n",
    "            # print(logits.shape)\n",
    "            logits = logits[:, -1, :]\n",
    "            # print(logits.shape)\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # print(idx_next.shape)\n",
    "            idx = torch.cat((idx, idx_next),dim=1)\n",
    "            \n",
    "            # print(idx.shape)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "out, loss = model(xb, yb)\n",
    "print(out.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45172cab-26c7-499c-a3c9-5838151a85a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 31, 56, 12, 55, 28,  7, 29, 35, 49, 58, 36, 53, 24,  4, 48, 24, 16,\n",
       "         22, 45, 27, 24, 34, 64,  5, 30, 21, 53, 16, 55, 20, 42, 46, 57, 34,  4,\n",
       "         60, 24, 24, 62, 39, 58, 48, 57, 41, 25, 54, 61, 24, 17, 30, 31, 28, 63,\n",
       "         39, 53,  8, 55, 44, 64, 57,  3, 37, 57,  3, 64, 18,  7, 61,  6, 11, 43,\n",
       "         17, 49, 64, 62, 48, 45, 15, 23, 18, 15, 46, 57,  2, 47, 35, 35,  8, 27,\n",
       "         40, 64, 16, 52, 62, 13,  1, 25, 57,  3,  9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = model.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_token=100)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f374fc3e-a790-4282-98fb-3a5d328711fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 101])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape #B,max token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705e6148-bbfd-4628-acd8-0eb98996b566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568a3bf-7030-48df-bb91-521befd588b8",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2becd7a2-6c2a-4bfd-87f6-f77b53e779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04f89943-4c96-4fb9-b647-9426bd42dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "# optimizer = optimizer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64c9b210-0fd0-496e-b0e9-73edc71e9e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.729414939880371\n",
      "2.608893394470215\n",
      "2.5848662853240967\n",
      "2.4988811016082764\n",
      "2.4509129524230957\n",
      "2.384185552597046\n",
      "2.4576575756073\n",
      "2.4058115482330322\n",
      "2.39339280128479\n",
      "2.5372300148010254\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    xb,yb = xb.to(device), yb.to(device)\n",
    "    logits, loss= model(xb, yb)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%1000==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d7c9c4-f6b7-419f-b4bf-84c7e7d22f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 16, 33, 15, 39, 42, 53, 53, 52, 48, 59,  1, 41, 47, 43,  1, 57, 58,\n",
       "          1, 58,  1, 58, 56, 43, 43,  1, 21, 21, 27, 24, 17, 26, 30, 17, 32, 46,\n",
       "         39, 52, 42,  1, 58,  6,  1, 39, 45, 46, 39, 58, 46,  6,  0, 25, 21, 10,\n",
       "          1, 18, 53, 50,  5, 57, 58, 53, 56, 43,  1, 25, 21, 44,  1, 53, 57,  1,\n",
       "         58, 46, 53,  1, 45, 43, 39, 58, 11,  1, 58, 47, 57, 46, 43, 43, 56,  1,\n",
       "         50, 47, 42,  1, 39, 50,  5, 57, 58,  1, 40]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "idx = model.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_token=100)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa3aa882-c710-490f-8749-a1f6967cf905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDUCadoonju cie st t tree IIOLENREThand t, aghath,\\nMI: Fol'store MIf os tho geat; tisheer lid al'st b\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d811e9-1a53-4dff-a804-a0d244ee9007",
   "metadata": {},
   "source": [
    "### Mathematical trick in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e917e4-73fa-46c6-a99c-9068b210b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf0e23-076e-4935-a94f-4507d2e83582",
   "metadata": {},
   "source": [
    "we want say the 5th token to have information of the 1st, 2nd,..,4th tokens. One way is to take the average of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e8a0f-d472-4f73-b40c-f0a1763a74e3",
   "metadata": {},
   "source": [
    "#### Averaging over previous time dimnension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e5b46bb-1011-4399-878b-0759d6c89a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros(B,T,C)\n",
    "#taking an average of time<=t\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1,:]\n",
    "        xbow[b,t] = xprev.mean(dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfa0e5a3-d398-46f5-aa35-926a113e88d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bfc518e-d82f-46c9-af5a-bba38167aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec1d8490-8224-4d84-83e8-01927e2f383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77783733-6c26-49e4-b8f6-4e916c874067",
   "metadata": {},
   "source": [
    "#### Running average over time using matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9b8ed55-72d3-459b-943b-96fc538aa545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "b=tensor([[2, 7],\n",
      "        [6, 4],\n",
      "        [6, 5]])\n",
      "c=tensor([[14, 16],\n",
      "        [14, 16],\n",
      "        [14, 16]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones((3,3), dtype=torch.long)\n",
    "print(f\"{a=}\")\n",
    "b = torch.randint(0,10,(3,2))\n",
    "print(f\"{b=}\")\n",
    "c = a @ b\n",
    "print(f\"{c=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5edda0a1-d1a7-4dcf-bb84-9d07118b7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones((3,3)))\n",
    "print(f\"{a=}\")\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "print(f\"{b=}\")\n",
    "c = a @ b\n",
    "print(f\"{c=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65cdb153-0a0d-43ca-8fb8-468aac483c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6667, 0.3333]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(dim=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58b0dfdd-6b7e-40c9-809d-463981ac71e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abb7f8e0-bfae-4dda-b5d1-69beaf5e3ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones((3,3)))/a.sum(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15d1ac26-c64b-4019-84d9-42ea865e9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones((3,3)))/a.sum(dim=1, keepdims=True)\n",
    "print(f\"{a=}\")\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "print(f\"{b=}\")\n",
    "c = a @ b\n",
    "print(f\"{c=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea0dde-d95e-44cf-a4fc-0fb2884e2f08",
   "metadata": {},
   "source": [
    "#### Tensorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef9febbd-13b8-4ec7-b344-ca0de01efff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07b0f43e-5581-45c2-b598-93d55ef49381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei/wei.sum(dim=1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088db57-46e2-4846-90d6-8dc8e3f1b672",
   "metadata": {},
   "source": [
    "wei shape (T,T) is converted to (B,T,T) while multiplying with x of shape (B,T,C). this is batch matrix multiply. for each batch there is (T, T) multiplying (T, C) dimension matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27c97ec1-b115-4e7e-a53b-dfee19f23c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = wei @ x \n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46e77384-250d-4824-984f-997eafd706a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0cda51e-7503-4f3e-a23a-f0f260665d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e2a8ae9-f5e9-4949-a5d0-0018e620b1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.allclose(xbow[0], xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1fc8ceb-06a8-49f8-bf2d-fd424b1e3fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3199,  0.0545,  0.0688,  0.0927, -0.0682, -0.1342,  0.2421,  0.0694,\n",
       "         0.0084,  0.0020,  0.0712,  0.2527,  0.1685,  0.3348, -0.2312, -0.0436,\n",
       "        -0.1015, -0.2593, -0.1630, -0.3015, -0.2293, -0.4071, -0.1299, -0.1641])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[(xbow==xbow2)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ec6a659-d31e-420f-b90e-f01a53c1a8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3199,  0.0545,  0.0688,  0.0927, -0.0682, -0.1342,  0.2421,  0.0694,\n",
       "         0.0084,  0.0020,  0.0712,  0.2527,  0.1685,  0.3348, -0.2312, -0.0436,\n",
       "        -0.1015, -0.2593, -0.1630, -0.3015, -0.2293, -0.4071, -0.1299, -0.1641])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[(xbow==xbow2)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec8f52cb-a317-4c3a-8909-970635ef37ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [False,  True],\n",
       "         [False, False],\n",
       "         [ True,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [False,  True],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [False, False],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [False,  True],\n",
       "         [False, False],\n",
       "         [False, False]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True, False]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow==xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d9d7f3e-483e-4829-af1c-7d6e00f054d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]),\n",
       " tensor([[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[-1], xbow2[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2397d-f85a-4de0-9be5-8a62d2e04320",
   "metadata": {},
   "source": [
    "#### Doing the same calculation using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a9656be-8485-4ca6-8ee2-e9d9dc2d1a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones((T,T)))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40719d6-9c7a-44a9-8b64-26af0667b0a8",
   "metadata": {},
   "source": [
    "wei.masked_fill(tril==0, float('-inf')) => inf means there's no connection between future and current token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06a08fea-fc40-43b8-8eb7-055e541fc3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3839cdc3-bf68-4e07-86df-71366169b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3 = wei @ x\n",
    "xbow3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4221bfe6-dc12-42c7-996b-06f7af0b9b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [False,  True],\n",
       "         [False, False],\n",
       "         [ True,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [False,  True],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [False, False],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [ True,  True],\n",
       "         [False, False],\n",
       "         [False,  True],\n",
       "         [False, False],\n",
       "         [False, False]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True, False]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow==xbow3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e61f59-fca4-48be-b9e2-a825c7db2f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
